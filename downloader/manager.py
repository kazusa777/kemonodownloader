import os
import aiohttp
import aiofiles
import asyncio


async def download_file(session, url, save_path, sem):
    async with sem:
        try:
            async with session.get(url) as resp:
                if resp.status == 200:
                    async with aiofiles.open(save_path, "wb") as f:
                        await f.write(await resp.read())
                    print(f"âœ… ä¸‹è¼‰å®Œæˆ: {save_path}")
                else:
                    print(f"âŒ ä¸‹è¼‰å¤±æ•—: {url} ({resp.status})")
        except Exception as e:
            print(f"âŒ ä¸‹è¼‰ç•°å¸¸: {url} - {e}")

async def save_post_concurrent(post, base_path, session, sem):
    folder_name = post["title"]
    post_path = os.path.join(base_path, folder_name)
    os.makedirs(post_path, exist_ok=True)

    # ä¸‹è¼‰åœ–ç‰‡ï¼ˆé«˜ä¸¦ç™¼ä»»å‹™ä½‡åˆ—ï¼‰
    download_tasks = []
    for img in post["images"]:
        save_path = os.path.join(post_path, img["name"])
        download_tasks.append(download_file(session, img["url"], save_path, sem))
    if download_tasks:
        await asyncio.gather(*download_tasks)

    # ä¸‹è¼‰å…¶ä»–æª”æ¡ˆï¼ˆæŒ‰éœ€ï¼‰
    for f in post.get("files", []):
        save_path = os.path.join(post_path, f["name"])
        await download_file(session, f["url"], save_path, sem)

    # ä¿å­˜å¤–éƒ¨é€£çµ
    if post.get("external_links"):
        links_path = os.path.join(post_path, "external_links.txt")
        async with aiofiles.open(links_path, "w", encoding="utf-8") as f:
            await f.write("\n".join(post["external_links"]))
        print(f"ğŸ“ å·²å„²å­˜ï¼š{links_path}")


async def download_streamed_posts(post_stream, base_path, concurrency=10):
    sem = asyncio.Semaphore(concurrency)
    async with aiohttp.ClientSession() as session:
        async for post in post_stream:
            # å°æ¯ä¸€å€‹æ–°ç²å–åˆ°çš„è²¼æ–‡ç«‹åˆ»å•Ÿå‹•ä¸¦ç™¼ä¸‹è¼‰
            await save_post_concurrent(post, base_path, session, sem)
